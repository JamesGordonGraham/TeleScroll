import React, { useState, useRef, useEffect } from "react";
import { Button } from "@/components/ui/button";
import { Card, CardContent } from "@/components/ui/card";
import { Mic, MicOff, X } from "lucide-react";
import { useToast } from "@/hooks/use-toast";

interface VoiceInputProps {
  onVoiceInput: (text: string) => void;
  onClose: () => void;
}

export default function VoiceInput({ onVoiceInput, onClose }: VoiceInputProps) {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState("");
  const [isSupported, setIsSupported] = useState(false);
  const recognitionRef = useRef<any>(null);
  const { toast } = useToast();

  useEffect(() => {
    // Check if SpeechRecognition API is available in the browser
    if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
      setIsSupported(true);
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      recognitionRef.current = new SpeechRecognition();

      // Configure recognition properties for smooth real-time transcription
      recognitionRef.current.continuous = true; // Keep listening even if user pauses
      recognitionRef.current.interimResults = true; // Show results as they are being spoken
      recognitionRef.current.lang = 'en-US'; // Set language
      recognitionRef.current.maxAlternatives = 1; // Only get the best result
      
      // Event handler for when speech is recognized - provides real-time updates
      recognitionRef.current.onresult = (event: any) => {
        let finalTranscript = '';
        let interimTranscript = '';

        // Process all results from the last processed index
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const result = event.results[i];
          if (result.isFinal) {
            finalTranscript += result[0].transcript; // Finalized speech
          } else {
            interimTranscript += result[0].transcript; // Interim (still being spoken) speech
          }
        }

        // Update transcript with smooth real-time display
        setTranscript(prev => {
          // Keep existing final text and add new final + interim text
          const existingFinal = prev.split(' ').filter(word => word.trim()).join(' ');
          const newFinal = finalTranscript.trim();
          const newInterim = interimTranscript.trim();
          
          if (newFinal) {
            return existingFinal + (existingFinal ? ' ' : '') + newFinal + (newInterim ? ' ' + newInterim : '');
          } else {
            return existingFinal + (existingFinal && newInterim ? ' ' : '') + newInterim;
          }
        });
      };

      // Event handler for when listening stops
      recognitionRef.current.onend = () => {
        setIsListening(false);
      };

      // Event handler for errors
      recognitionRef.current.onerror = (event: any) => {
        console.error('Speech recognition error:', event.error);
        
        if (event.error === 'not-allowed') {
          toast({
            title: "Microphone Access Denied",
            description: "Please allow microphone access and try again",
            variant: "destructive",
          });
        } else if (event.error === 'network') {
          toast({
            title: "Network Error",
            description: "Please check your internet connection",
            variant: "destructive",
          });
        }
        
        setIsListening(false);
      };

      // Handle start event
      recognitionRef.current.onstart = () => {
        setIsListening(true);
      };
    }

    // Cleanup function: stop recognition when component unmounts
    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
    };
  }, [toast]);

  const startListening = () => {
    if (recognitionRef.current && isSupported) {
      setTranscript(""); // Clear previous transcript
      try {
        recognitionRef.current.start(); // Start listening
        toast({
          title: "Voice Input Started",
          description: "Start speaking - your words will appear in real-time",
        });
      } catch (error) {
        console.error('Failed to start recognition:', error);
        toast({
          title: "Voice Input Error", 
          description: "Failed to start voice recognition. Please try again.",
          variant: "destructive",
        });
      }
    } else {
      toast({
        title: "Voice Input Not Supported",
        description: "Your browser doesn't support voice input",
        variant: "destructive",
      });
    }
  };

  const stopListening = () => {
    if (recognitionRef.current) {
      recognitionRef.current.stop(); // Stop listening
      setIsListening(false);
      toast({
        title: "Voice Input Stopped",
        description: "Voice recording has been stopped",
      });
    }
  };

  const handleAddToScript = () => {
    if (transcript.trim()) {
      onVoiceInput(transcript.trim()); // Pass the recognized text to the parent component
      toast({
        title: "Text Added to Script",
        description: "Voice input has been added to your script editor",
      });
      onClose(); // Close the modal
    } else {
      toast({
        title: "No Text to Add",
        description: "Please record some speech first",
        variant: "destructive",
      });
    }
  };

  const clearTranscript = () => {
    setTranscript("");
    toast({
      title: "Transcript Cleared",
      description: "Voice input text has been cleared",
    });
  };

  if (!isSupported) {
    return (
      <Card className="w-full max-w-md mx-auto bg-white shadow-xl">
        {/* Blue Header */}
        <div className="bg-gradient-to-r from-blue-500 to-cyan-500 p-4 rounded-t-lg">
          <div className="flex justify-between items-center">
            <div className="flex items-center">
              <MicOff className="h-5 w-5 text-white mr-2" />
              <h3 className="text-lg font-semibold text-white">Voice Input</h3>
            </div>
            <Button
              variant="ghost"
              size="sm"
              onClick={onClose}
              className="text-white hover:bg-white/20"
            >
              <X className="h-4 w-4" />
            </Button>
          </div>
        </div>
        <CardContent className="p-6 text-center">
          <div className="w-20 h-20 mx-auto bg-gray-300 rounded-full flex items-center justify-center mb-4">
            <MicOff className="h-8 w-8 text-gray-600" />
          </div>
          <h4 className="text-lg font-semibold mb-2">Voice Input Not Supported</h4>
          <p className="text-gray-600 mb-4">
            Your browser doesn't support voice input. Please use Chrome, Edge, or Safari.
          </p>
          <Button onClick={onClose} className="bg-blue-500 hover:bg-blue-600">Close</Button>
        </CardContent>
      </Card>
    );
  }

  return (
    <Card className="w-full max-w-md mx-auto bg-white shadow-xl">
      {/* Blue Header like in the screenshot */}
      <div className="bg-gradient-to-r from-blue-500 to-cyan-500 p-4 rounded-t-lg">
        <div className="flex justify-between items-center">
          <div className="flex items-center">
            <Mic className="h-5 w-5 text-white mr-2" />
            <h3 className="text-lg font-semibold text-white">Voice Input</h3>
          </div>
          <Button
            variant="ghost"
            size="sm"
            onClick={onClose}
            className="text-white hover:bg-white/20"
          >
            <X className="h-4 w-4" />
          </Button>
        </div>
      </div>

      <CardContent className="p-6">
        {!isListening && !transcript ? (
          // Initial state - show big blue microphone button like in screenshot
          <div className="text-center py-8">
            <div className="mb-6">
              <button 
                onClick={startListening}
                className="w-20 h-20 mx-auto bg-gradient-to-br from-blue-500 to-blue-600 rounded-full flex items-center justify-center shadow-lg hover:from-blue-600 hover:to-blue-700 transition-all duration-200 hover:scale-105"
              >
                <Mic className="h-8 w-8 text-white" />
              </button>
            </div>
            <h4 className="text-lg font-semibold mb-2">Ready to listen</h4>
            <p className="text-gray-600 mb-6">Click the microphone to start voice input</p>
          </div>
        ) : (
          // Recording/transcript state
          <div>
            <div className="text-center mb-6">
              <div className={`w-16 h-16 mx-auto rounded-full flex items-center justify-center shadow-lg transition-all duration-300 ${
                isListening 
                  ? 'bg-gradient-to-br from-red-500 to-red-600 animate-pulse' 
                  : 'bg-gradient-to-br from-blue-500 to-blue-600'
              }`}>
                {isListening ? <MicOff className="h-6 w-6 text-white" /> : <Mic className="h-6 w-6 text-white" />}
              </div>
              <p className="mt-3 text-sm font-medium">
                {isListening ? (
                  <span className="text-red-600">ðŸ”´ Not Listening</span>
                ) : (
                  <span className="text-gray-600">Ready</span>
                )}
              </p>
              <div className="mt-3 space-x-2">
                {isListening ? (
                  <Button
                    variant="outline"
                    size="sm"
                    onClick={stopListening}
                    className="border-red-500 text-red-600 hover:bg-red-50"
                  >
                    Stop Listening
                  </Button>
                ) : (
                  <Button
                    size="sm"
                    onClick={startListening}
                    className="bg-blue-500 hover:bg-blue-600"
                  >
                    Start Voice Input
                  </Button>
                )}
              </div>
            </div>

            <div className="mb-4">
              <h4 className="text-sm font-medium mb-2">Real-time Transcript:</h4>
              <div className="min-h-[100px] p-4 border-2 border-gray-200 rounded-lg bg-gray-50 text-sm">
                {transcript || (isListening ? 'Listening... speak clearly' : 'Click "Start Voice Input" and begin speaking')}
              </div>
              <div className="mt-2 text-xs text-gray-500">
                â€¢ Speak clearly and at a normal pace for best results<br/>
                â€¢ Your words will appear in real-time as you speak<br/>
                â€¢ The system will continue listening until you click "Stop"<br/>
                â€¢ Click "Add to Script Editor" to insert the text into your teleprompter
              </div>
            </div>

            <div className="flex gap-2">
              <Button
                variant="outline"
                onClick={clearTranscript}
                disabled={!transcript}
                size="sm"
              >
                Clear Text
              </Button>
              <Button
                onClick={handleAddToScript}
                disabled={!transcript.trim()}
                className="flex-1 bg-gradient-to-r from-green-500 to-green-600 hover:from-green-600 hover:to-green-700"
              >
                Add to Script Editor
              </Button>
              <Button
                variant="outline"
                onClick={onClose}
                size="sm"
              >
                Cancel
              </Button>
            </div>
          </div>
        )}
      </CardContent>
    </Card>
  );
}